# Subregular Language Learning
This is a project that extends the work done by Van der Poel et. al in [MLRegTest](https://arxiv.org/abs/2304.07687) to a set of larger transformer models including Google's [CANINE-c](https://huggingface.co/google/canine-c) (tokenization-free transformer encoder trained on autoregressive character loss), [CANINE-s](https://huggingface.co/google/canine-s) (same thing but trained on subword loss instead), and [BERT](https://huggingface.co/google-bert/bert-base-uncased).

Instructions WIP
